# ==========================================================
# B5 ‚Äì MODEL MACHINE LEARNING & GUI
# ==========================================================

import warnings
warnings.filterwarnings("ignore")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, silhouette_score, davies_bouldin_score, calinski_harabasz_score

plt.style.use('ggplot')

# ==========================================================
# LOAD D·ªÆ LI·ªÜU
# ==========================================================
@st.cache_data
def load_data():
    """Load v√† x·ª≠ l√Ω d·ªØ li·ªáu"""
    try:
        df = pd.read_csv("goldstock_cleaned_B2.csv")
        df["Date"] = pd.to_datetime(df["Date"])
    except:
        df = pd.read_csv("goldstock v2.csv", sep=";")
        if "Column1" in df.columns:
            df.drop(columns=["Column1"], inplace=True)
        if "Unnamed: 0" in df.columns:
            df.drop(columns=["Unnamed: 0"], inplace=True)
        df.columns = df.columns.str.strip()
        numeric_cols = ["Volume", "Open", "High", "Low", "Close/Last"]
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        try:
            df["Date"] = pd.to_datetime(df["Date"], format="%d/%m/%Y", errors='coerce')
        except:
            df["Date"] = pd.to_datetime(df["Date"], infer_datetime_format=True, errors='coerce')
        df = df.dropna()
        df = df[df.duplicated() == False].reset_index(drop=True)
    
    return df

def render_app():
    """Render B5 app content inside an existing Streamlit page."""
    st.title("üìä B5 - Machine Learning Model & Visualization")
    st.markdown("---")

    # Load data
    df = load_data()
    quantitative_cols = df.select_dtypes(include=["int64", "float64"]).columns.tolist()

    st.success(f"‚úÖ D·ªØ li·ªáu ƒë√£ load: {len(df)} h√†ng, {df.shape[1]} c·ªôt")

    # T·∫°o tabs
    tab1, tab2 = st.tabs(["üéØ K-Means Clustering", "üìà Linear Regression Prediction"])

    # ==========================================================
    # TAB 1: K-MEANS CLUSTERING
    # ==========================================================
    with tab1:
        st.header("üéØ Ph√¢n c·ª•m d·ªØ li·ªáu (K-Means Clustering)")
        
        st.info("‚ö†Ô∏è **L∆∞u √Ω:** M√¥ h√¨nh K-Means d∆∞·ªõi ƒë√¢y ch·ªâ mang t√≠nh minh h·ªça ƒë·ªÉ ph√¢n c·ª•m d·ªØ li·ªáu. M·ª•c ƒë√≠ch l√† l√†m r√µ c·∫•u tr√∫c d·ªØ li·ªáu, kh√¥ng ƒë√°nh gi√° cao hi·ªáu su·∫•t d·ª± b√°o.")
        
        # Sidebar controls
        st.sidebar.header("‚öôÔ∏è K-Means Settings")
        k = st.sidebar.slider(
            "S·ªë c·ª•m (Number of clusters)",
            min_value=2,
            max_value=6,
            value=3,
            step=1
        )
        
        random_state = st.sidebar.number_input("Random State", value=42, step=1)
        
        # Apply KMeans
        with st.spinner("ƒêang ph√¢n c·ª•m d·ªØ li·ªáu..."):
            kmeans = KMeans(n_clusters=k, random_state=random_state, n_init=10)
            df["Cluster"] = kmeans.fit_predict(df[quantitative_cols])
        
        # ==========================================================
        # CLUSTER VISUALIZATION
        # ==========================================================
        st.subheader("üìä Tr·ª±c quan h√≥a ph√¢n c·ª•m")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Scatter Plot: Open vs Close**")
            fig, ax = plt.subplots(figsize=(10, 6))
            scatter = ax.scatter(df["Open"], df["Close/Last"], 
                               c=df["Cluster"], cmap='Set2', s=80, alpha=0.6, 
                               edgecolors='black', linewidth=0.5)
            ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],
                      c='red', marker='X', s=300, edgecolors='black', linewidth=2,
                      label='Centroids', zorder=5)
            ax.set_xlabel("Open Price ($)", fontsize=11, fontweight='bold')
            ax.set_ylabel("Close Price ($)", fontsize=11, fontweight='bold')
            ax.set_title(f"K-Means Clustering (K={k})", fontsize=12, fontweight='bold')
            ax.legend()
            ax.grid(True, alpha=0.3)
            plt.colorbar(scatter, ax=ax, label='Cluster')
            st.pyplot(fig)
        
        with col2:
            st.write("**Scatter Plot: Low vs High**")
            fig, ax = plt.subplots(figsize=(10, 6))
            scatter = ax.scatter(df["Low"], df["High"],
                               c=df["Cluster"], cmap='Set2', s=80, alpha=0.6, 
                               edgecolors='black', linewidth=0.5)
            ax.scatter(kmeans.cluster_centers_[:, 2], kmeans.cluster_centers_[:, 3],
                      c='red', marker='X', s=300, edgecolors='black', linewidth=2,
                      label='Centroids', zorder=5)
            ax.set_xlabel("Low Price ($)", fontsize=11, fontweight='bold')
            ax.set_ylabel("High Price ($)", fontsize=11, fontweight='bold')
            ax.set_title(f"K-Means Clustering (K={k})", fontsize=12, fontweight='bold')
            ax.legend()
            ax.grid(True, alpha=0.3)
            plt.colorbar(scatter, ax=ax, label='Cluster')
            st.pyplot(fig)
        
        # Time series with clusters
        st.write("### ‚è∞ Ph√¢n b·ªë c·ª•m theo th·ªùi gian")
        fig, ax = plt.subplots(figsize=(14, 6))
        colors = plt.cm.Set2(np.linspace(0, 1, k))
        for cluster in range(k):
            cluster_data = df[df["Cluster"] == cluster]
            ax.scatter(cluster_data["Date"], cluster_data["Close/Last"],
                      label=f"Cluster {cluster}", alpha=0.6, s=40, color=colors[cluster])
        ax.set_xlabel("Date", fontsize=11, fontweight='bold')
        ax.set_ylabel("Close Price ($)", fontsize=11, fontweight='bold')
        ax.set_title(f"Gold Price with K-Means Clusters (K={k})", fontsize=12, fontweight='bold')
        ax.legend(loc='best')
        ax.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        st.pyplot(fig)
        
        # ==========================================================
        # CLUSTER STATISTICS
        # ==========================================================
        st.write("### üìä Th·ªëng k√™ chi ti·∫øt t·ª´ng c·ª•m")
        cluster_stats = df.groupby("Cluster")[quantitative_cols].agg(['mean', 'min', 'max', 'std'])
        st.dataframe(cluster_stats, use_container_width=True)
        
        # Cluster sizes
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("### üìä K√≠ch th∆∞·ªõc c·ª•m")
            cluster_sizes = df["Cluster"].value_counts().sort_index()
            
            fig, ax = plt.subplots(figsize=(8, 5))
            ax.bar(cluster_sizes.index, cluster_sizes.values, color=colors, 
                   edgecolor='black', linewidth=1.5)
            ax.set_xlabel("Cluster", fontsize=11, fontweight='bold')
            ax.set_ylabel("Number of Data Points", fontsize=11, fontweight='bold')
            ax.set_title(f"Cluster Size Distribution (K={k})", fontsize=12, fontweight='bold')
            ax.set_xticks(range(k))
            for i, v in enumerate(cluster_sizes.values):
                ax.text(i, v + 5, str(v), ha='center', fontweight='bold')
            ax.grid(True, alpha=0.3, axis='y')
            st.pyplot(fig)
        
        with col2:
            st.write("### üìä T·ª∑ l·ªá ph·∫ßn trƒÉm")
            fig, ax = plt.subplots(figsize=(8, 5))
            ax.pie(cluster_sizes.values, 
                   labels=[f"Cluster {i}\n({v} points)" for i, v in enumerate(cluster_sizes.values)],
                   colors=colors, autopct='%1.1f%%', startangle=90, explode=[0.05]*k)
            ax.set_title(f"Cluster Distribution (K={k})", fontsize=12, fontweight='bold')
            st.pyplot(fig)
        
        # ==========================================================
        # CLUSTER CHARACTERISTICS
        # ==========================================================
        st.write("### üîç ƒê·∫∑c ƒëi·ªÉm c·ªßa t·ª´ng c·ª•m")
        for cluster in range(k):
            with st.expander(f"üìå Cluster {cluster} - {len(df[df['Cluster'] == cluster])} ƒëi·ªÉm d·ªØ li·ªáu"):
                cluster_data = df[df["Cluster"] == cluster]
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Gi√° Close TB", f"${cluster_data['Close/Last'].mean():.2f}")
                    st.metric("Gi√° Min", f"${cluster_data['Close/Last'].min():.2f}")
                
                with col2:
                    st.metric("Gi√° Max", f"${cluster_data['Close/Last'].max():.2f}")
                    st.metric("Volume TB", f"{cluster_data['Volume'].mean():,.0f}")
                
                with col3:
                    st.metric(
                        "T·ª´ ng√†y",
                        cluster_data['Date'].min().strftime("%d/%m/%Y")
                    )
                    st.metric(
                        "ƒê·∫øn ng√†y",
                        cluster_data['Date'].max().strftime("%d/%m/%Y")
                    )
        
        # ==========================================================
        # MODEL EVALUATION
        # ==========================================================
        st.write("### üìä ƒê√°nh gi√° m√¥ h√¨nh K-Means")
        
        inertia = kmeans.inertia_
        silhouette = silhouette_score(df[quantitative_cols], df["Cluster"])
        davies_bouldin = davies_bouldin_score(df[quantitative_cols], df["Cluster"])
        calinski = calinski_harabasz_score(df[quantitative_cols], df["Cluster"])
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Inertia", f"{inertia:.2f}")
            st.caption("Lower is better")
        
        with col2:
            st.metric("Silhouette Score", f"{silhouette:.4f}")
            st.caption("Higher is better (-1 to 1)")
        
        with col3:
            st.metric("Davies-Bouldin", f"{davies_bouldin:.4f}")
            st.caption("Lower is better")
        
        with col4:
            st.metric("Calinski-Harabasz", f"{calinski:.2f}")
            st.caption("Higher is better")
        
        # Interpretation
        if silhouette > 0.5:
            st.success(f"‚úÖ Silhouette Score = {silhouette:.4f} - Ph√¢n c·ª•m T·ªêT")
        elif silhouette > 0.3:
            st.warning(f"‚ö†Ô∏è Silhouette Score = {silhouette:.4f} - Ph√¢n c·ª•m TRUNG B√åNH")
        else:
            st.error(f"‚ùå Silhouette Score = {silhouette:.4f} - Ph√¢n c·ª•m C·∫¶N C·∫¢I THI·ªÜN")
        
        # Sample data
        st.write("### üìù D·ªØ li·ªáu m·∫´u sau ph√¢n c·ª•m")
        display_cols = ["Date", "Open", "High", "Low", "Close/Last", "Volume", "Cluster"]
        st.dataframe(df[display_cols].head(20), use_container_width=True)

    # ==========================================================
    # TAB 2: LINEAR REGRESSION
    # ==========================================================
    with tab2:
        st.header("üìà D·ª± ƒëo√°n gi√° v√†ng (Linear Regression)")
        
        st.info("üîÆ **M√¥ h√¨nh Linear Regression ƒë·ªÉ d·ª± ƒëo√°n gi√° v√†ng ƒë·∫øn nƒÉm 2027**")
        
        # Prepare data
        df_model = df.copy()
        df_model['Days'] = (df_model['Date'] - df_model['Date'].min()).dt.days
        
        X = df_model[['Days']].values
        y = df_model['Close/Last'].values
        
        # Train model
        with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
            lr_model = LinearRegression()
            lr_model.fit(X, y)
            y_pred_train = lr_model.predict(X)
        
        # Calculate metrics
        mse = mean_squared_error(y, y_pred_train)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y, y_pred_train)
        r2 = r2_score(y, y_pred_train)
        
        # Display metrics
        st.write("### üìä Hi·ªáu su·∫•t m√¥ h√¨nh")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("R¬≤ Score", f"{r2:.4f}")
            st.caption("Closer to 1 is better")
        
        with col2:
            st.metric("RMSE", f"${rmse:.2f}")
            st.caption("Root Mean Squared Error")
        
        with col3:
            st.metric("MAE", f"${mae:.2f}")
            st.caption("Mean Absolute Error")
        
        with col4:
            st.metric("MSE", f"${mse:.2f}")
            st.caption("Mean Squared Error")
        
        # Model interpretation
        if r2 > 0.7:
            st.success(f"‚úÖ R¬≤ = {r2:.4f} - M√¥ h√¨nh T·ªêT")
        elif r2 > 0.5:
            st.warning(f"‚ö†Ô∏è R¬≤ = {r2:.4f} - M√¥ h√¨nh TRUNG B√åNH")
        else:
            st.error(f"‚ùå R¬≤ = {r2:.4f} - M√¥ h√¨nh Y·∫æU")
        
        # ==========================================================
        # FUTURE PREDICTION
        # ==========================================================
        st.write("### üîÆ D·ª± ƒëo√°n t∆∞∆°ng lai")
        
        # Sidebar controls
        st.sidebar.header("‚öôÔ∏è Prediction Settings")
        end_year = st.sidebar.selectbox("D·ª± ƒëo√°n ƒë·∫øn nƒÉm", [2025, 2026, 2027, 2028, 2030], index=2)
        
        # Generate future dates
        last_date = df_model['Date'].max()
        target_date = pd.Timestamp(f'{end_year}-12-31')
        
        future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), end=target_date, freq='D')
        future_days = (future_dates - df_model['Date'].min()).days.values.reshape(-1, 1)
        
        # Predict
        future_prices = lr_model.predict(future_days)
        
        future_df = pd.DataFrame({
            'Date': future_dates,
            'Predicted_Price': future_prices
        })
        
        # ==========================================================
        # VISUALIZATION
        # ==========================================================
        st.write("### üìä Bi·ªÉu ƒë·ªì d·ª± ƒëo√°n")
        
        fig, ax = plt.subplots(figsize=(16, 7))
        
        # Historical actual
        ax.plot(df_model['Date'], df_model['Close/Last'], 
                linewidth=2, color='steelblue', label='Historical Actual Price', alpha=0.8)
        
        # Historical fitted
        ax.plot(df_model['Date'], y_pred_train, 
                linewidth=2, color='orange', linestyle='--', label='Linear Regression Fit', alpha=0.7)
        
        # Future prediction
        ax.plot(future_df['Date'], future_df['Predicted_Price'], 
                linewidth=2.5, color='red', linestyle='-', label=f'Future Prediction (to {end_year})', alpha=0.8)
        
        # Confidence interval
        std_error = np.std(y - y_pred_train)
        ax.fill_between(future_df['Date'], 
                        future_df['Predicted_Price'] - 1.96*std_error,
                        future_df['Predicted_Price'] + 1.96*std_error,
                        alpha=0.2, color='red', label='95% Confidence Interval')
        
        ax.set_xlabel("Date", fontsize=12, fontweight='bold')
        ax.set_ylabel("Price (USD/oz)", fontsize=12, fontweight='bold')
        ax.set_title(f"Gold Price Prediction using Linear Regression (to {end_year})", 
                     fontsize=14, fontweight='bold')
        ax.legend(loc='best', fontsize=10)
        ax.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        plt.tight_layout()
        st.pyplot(fig)
        
        # ==========================================================
        # PREDICTION STATISTICS
        # ==========================================================
        st.write("### üìä Th·ªëng k√™ d·ª± ƒëo√°n")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**D·ª± ƒëo√°n gi√° v√†ng:**")
            prediction_stats = {
                "Date": [
                    f"Last Historical ({last_date.date()})",
                    f"End of 2025",
                    f"End of 2026",
                    f"End of {end_year}"
                ],
                "Predicted Price": [
                    f"${df_model['Close/Last'].iloc[-1]:.2f}",
                    f"${lr_model.predict([[((pd.Timestamp('2025-12-31') - df_model['Date'].min()).days)]])[0]:.2f}",
                    f"${lr_model.predict([[((pd.Timestamp('2026-12-31') - df_model['Date'].min()).days)]])[0]:.2f}",
                    f"${lr_model.predict([[((pd.Timestamp(f'{end_year}-12-31') - df_model['Date'].min()).days)]])[0]:.2f}"
                ]
            }
            st.dataframe(pd.DataFrame(prediction_stats), use_container_width=True)
        
        with col2:
            st.write("**Th√¥ng s·ªë m√¥ h√¨nh:**")
            model_params = {
                "Parameter": [
                    "Slope (H·ªá s·ªë g√≥c)",
                    "Intercept (H·∫±ng s·ªë)",
                    "Daily Price Change",
                    "Yearly Price Change"
                ],
                "Value": [
                    f"{lr_model.coef_[0]:.4f}",
                    f"${lr_model.intercept_:.2f}",
                    f"${lr_model.coef_[0]:.4f}/day",
                    f"${lr_model.coef_[0]*365:.2f}/year"
                ]
            }
            st.dataframe(pd.DataFrame(model_params), use_container_width=True)
        
        # Model equation
        st.write("### üìê Ph∆∞∆°ng tr√¨nh h·ªìi quy")
        st.latex(f"Price = {lr_model.intercept_:.2f} + {lr_model.coef_[0]:.4f} \\times Days")
        
        # ==========================================================
        # INTERPRETATION
        # ==========================================================
        st.write("### üí° Gi·∫£i th√≠ch k·∫øt qu·∫£")
        
        trend_direction = "tƒÉng" if lr_model.coef_[0] > 0 else "gi·∫£m"
        trend_emoji = "üìà" if lr_model.coef_[0] > 0 else "üìâ"
        
        st.markdown(f"""
        **√ù nghƒ©a c√°c ch·ªâ s·ªë:**
        - **R¬≤ = {r2:.4f}**: M√¥ h√¨nh gi·∫£i th√≠ch {r2*100:.2f}% s·ª± bi·∫øn ƒë·ªông c·ªßa gi√° v√†ng
        - **RMSE = ${rmse:.2f}**: Sai s·ªë trung b√¨nh kho·∫£ng ${rmse:.2f}
        - **Slope = {lr_model.coef_[0]:.4f}**: Gi√° v√†ng {trend_direction} trung b√¨nh ${abs(lr_model.coef_[0]):.4f}/ng√†y
        
        **Xu h∆∞·ªõng:**
        {trend_emoji} Gi√° v√†ng c√≥ xu h∆∞·ªõng **{trend_direction}** ƒë·ªÅu ƒë·∫∑n v·ªõi t·ªëc ƒë·ªô **${abs(lr_model.coef_[0]*365):.2f}/nƒÉm**
        
        **D·ª± ƒëo√°n ƒë·∫øn {end_year}:**
        - Gi√° d·ª± ki·∫øn: **${lr_model.predict([[((pd.Timestamp(f'{end_year}-12-31') - df_model['Date'].min()).days)]])[0]:.2f}**
        - Kho·∫£ng tin c·∫≠y 95%: **${lr_model.predict([[((pd.Timestamp(f'{end_year}-12-31') - df_model['Date'].min()).days)]])[0] - 1.96*std_error:.2f}** - **${lr_model.predict([[((pd.Timestamp(f'{end_year}-12-31') - df_model['Date'].min()).days)]])[0] + 1.96*std_error:.2f}**
        """)
        
        st.warning("‚ö†Ô∏è **L∆∞u √Ω:** D·ª± ƒëo√°n d√†i h·∫°n v·ªõi Linear Regression c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c do gi·∫£ ƒë·ªãnh xu h∆∞·ªõng tuy·∫øn t√≠nh. Gi√° v√†ng b·ªã ·∫£nh h∆∞·ªüng b·ªüi nhi·ªÅu y·∫øu t·ªë kinh t·∫ø, ch√≠nh tr·ªã ph·ª©c t·∫°p.")
        
        # ==========================================================
        # DOWNLOAD DATA
        # ==========================================================
        st.write("### üíæ T·∫£i d·ªØ li·ªáu d·ª± ƒëo√°n")
        
        download_df = pd.DataFrame({
            'Date': list(df_model['Date']) + list(future_df['Date']),
            'Actual_Price': list(df_model['Close/Last']) + [np.nan]*len(future_df),
            'Predicted_Price': list(y_pred_train) + list(future_df['Predicted_Price']),
            'Type': ['Historical']*len(df_model) + ['Future']*len(future_df)
        })
        
        csv_data = download_df.to_csv(index=False)
        st.download_button(
            label="üì• Download Prediction CSV",
            data=csv_data,
            file_name=f"gold_price_prediction_to_{end_year}.csv",
            mime="text/csv"
        )

    # ==========================================================
    # FOOTER
    # ==========================================================
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center'>
        <p><b>B5 - Machine Learning Model & GUI</b></p>
        <p>Gold Price Data Mining Project</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    st.set_page_config(page_title="Gold Price Data Mining - B5", layout="wide", page_icon="üìä")
    render_app()
