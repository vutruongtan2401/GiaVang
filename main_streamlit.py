# ==========================================================
# QUYTR√åNH PH√ÇN T√çCH D·ª∞ VI·ªÑN GI√Å V√ÄNG - STREAMLIT APP
# Gold Price Forecasting Dashboard
# ==========================================================

import warnings
warnings.filterwarnings("ignore")

import io
import os
import pandas as pd
import numpy as np
import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, silhouette_score

# Configuration
st.set_page_config(
    page_title="Gold Price Analysis",
    layout="wide",
    page_icon="üèÜ",
    initial_sidebar_state="expanded"
)

plt.style.use('ggplot')
sns.set_palette("husl")

# Custom CSS
st.markdown("""
<style>
    .stTabs [data-baseweb="tab-list"] button [data-testid="stMarkdownContainer"] p {
        font-size: 1.1rem;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================
# DATA LOADING & CACHING
# ============================================================
@st.cache_data
def load_default_data():
    """Load d·ªØ li·ªáu m·∫∑c ƒë·ªãnh"""
    try:
        df = pd.read_csv("goldstock v2.csv", sep=";")
        df.columns = df.columns.str.strip()
        
        if "Column1" in df.columns:
            df.drop(columns=["Column1"], inplace=True)
        if "Unnamed: 0" in df.columns:
            df.drop(columns=["Unnamed: 0"], inplace=True)
        
        numeric_cols = ["Volume", "Open", "High", "Low", "Close/Last"]
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        df["Date"] = pd.to_datetime(df["Date"], format="%d/%m/%Y", errors='coerce')
        df.sort_values("Date", inplace=True)
        df.reset_index(drop=True, inplace=True)
        
        return df
    except Exception as e:
        st.error(f"L·ªói load d·ªØ li·ªáu: {e}")
        return None

# ============================================================
# MAIN APP
# ============================================================
def main():
    # Sidebar Navigation
    st.sidebar.markdown("# üìä QUYTR√åNH PH√ÇN T√çCH D·ª∞ VI·ªÑN GI√Å V√ÄNG")
    st.sidebar.markdown("---")
    
    page = st.sidebar.radio(
        "üîç Ch·ªçn b∆∞·ªõc ph√¢n t√≠ch:",
        ["üè† Trang ch·ªß", "üì§ B1: M√¥ t·∫£ d·ªØ li·ªáu", "üßπ B2: L√†m s·∫°ch", 
         "üìà B3: Khai ph√° d·ªØ li·ªáu", "üîó B4: T∆∞∆°ng quan & PCA", "ü§ñ B5: M√¥ h√¨nh & D·ª± b√°o"]
    )
    
    # Load d·ªØ li·ªáu m·∫∑c ƒë·ªãnh
    df = load_default_data()
    
    if df is None:
        st.error("‚ùå Kh√¥ng th·ªÉ load d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra file goldstock v2.csv")
        return
    
    # ============================================================
    # TRANG CH·ª¶
    # ============================================================
    if page == "üè† Trang ch·ªß":
        st.title("üèÜ Ph√¢n T√≠ch D·ª± Vi·ªÖn Gi√° V√†ng")
        st.markdown("---")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("üìä S·ªë h√†ng", f"{len(df):,}")
        with col2:
            st.metric("üìã S·ªë c·ªôt", df.shape[1])
        with col3:
            st.metric("üìÖ Kho·∫£ng th·ªùi gian", f"{df['Date'].min().date()} ‚Üí {df['Date'].max().date()}")
        
        st.markdown("""
        ### üìå Quy tr√¨nh ph√¢n t√≠ch:
        
        1. **B1: M√¥ t·∫£ d·ªØ li·ªáu** - T·ªïng quan, ph√¢n lo·∫°i bi·∫øn, th·ªëng k√™
        2. **B2: L√†m s·∫°ch d·ªØ li·ªáu** - X·ª≠ l√Ω missing, outliers, validation
        3. **B3: Khai ph√° d·ªØ li·ªáu** - Ph√¢n t√≠ch ƒë∆°n bi·∫øn & ƒëa bi·∫øn
        4. **B4: T∆∞∆°ng quan & PCA** - Ma tr·∫≠n t∆∞∆°ng quan, l·ª±a ch·ªçn features
        5. **B5: M√¥ h√¨nh & D·ª± b√°o** - K-Means Clustering, Linear Regression
        
        ### üéØ M·ª•c ti√™u:
        Ph√¢n t√≠ch to√†n di·ªán d·ªØ li·ªáu gi√° v√†ng t·ª´ kh√°m ph√° ƒë·∫øn x√¢y d·ª±ng m√¥ h√¨nh d·ª± b√°o
        """)
        
        st.info("üëà Ch·ªçn m·ªôt b∆∞·ªõc t·ª´ menu b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu!")
    
    # ============================================================
    # B1: M√î T·∫¢ D·ªÆ LI·ªÜU
    # ============================================================
    elif page == "üì§ B1: M√¥ t·∫£ d·ªØ li·ªáu":
        st.title("B1 ‚Äî M√¥ T·∫£ D·ªØ Li·ªáu (Data Description)")
        st.markdown("---")
        
        # B1.1 - SHAPE
        st.header("üìä B1.1 - K√≠ch Th∆∞·ªõc D·ªØ Li·ªáu")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("üî¢ SHAPE", f"{df.shape}", delta=None)
        with col2:
            st.metric("üìà S·ªë d√≤ng", f"{df.shape[0]:,}")
        with col3:
            st.metric("üìã S·ªë c·ªôt", df.shape[1])
        
        # B1.2 - PH√ÇN LO·∫†I D·ªÆ LI·ªÜU
        st.header("üìã B1.2 - Ph√¢n Lo·∫°i D·ªØ Li·ªáu")
        
        numeric_cols = df.select_dtypes(include=["int64", "float64"]).columns.tolist()
        categorical_cols = df.select_dtypes(exclude=["int64", "float64"]).columns.tolist()
        
        classification_data = []
        for i, col in enumerate(df.columns, 1):
            col_type = "üî¢ Numerical (ƒê·ªãnh l∆∞·ª£ng)" if col in numeric_cols else "üìù Categorical (ƒê·ªãnh t√≠nh)"
            classification_data.append({
                "STT": i,
                "Column Name": col,
                "Data Type": col_type,
                "Type Detail": str(df[col].dtype)
            })
        
        classification_df = pd.DataFrame(classification_data)
        st.dataframe(classification_df, use_container_width=True, hide_index=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader(f"üî¢ C·ªôt ƒê·ªãnh L∆∞·ª£ng: {len(numeric_cols)}")
            for col in numeric_cols:
                st.write(f"   ‚úì {col}")
        
        with col2:
            st.subheader(f"üìù C·ªôt ƒê·ªãnh T√≠nh: {len(categorical_cols)}")
            for col in categorical_cols:
                st.write(f"   ‚úì {col}")
        
        # B1.3 - TH·ªêNG K√ä M√î T·∫¢
        st.header("üìä B1.3 - Th·ªëng K√™ M√¥ T·∫£")
        st.dataframe(df[numeric_cols].describe().T, use_container_width=True)
        
        # B1.4 - D·ªÆ LI·ªÜU M·∫™U
        st.header("üîπ B1.4 - D·ªØ Li·ªáu M·∫´u")
        st.dataframe(df.head(10), use_container_width=True)
    
    # ============================================================
    # B2: L√ÄM S·∫†CH D·ªÆ LI·ªÜU
    # ============================================================
    elif page == "üßπ B2: L√†m s·∫°ch":
        st.title("B2 ‚Äî L√†m S·∫°ch D·ªØ Li·ªáu (Data Cleaning)")
        st.markdown("---")
        
        numeric_cols = df.select_dtypes(include=["int64", "float64"]).columns.tolist()
        
        # B2.1 - MISSING VALUES
        st.header("üìä B2.1 - Ki·ªÉm Tra Missing Values")
        
        missing_df = pd.DataFrame({
            'C·ªôt': df.columns,
            'Missing Count': df.isnull().sum().values,
            'Missing %': (df.isnull().sum().values / len(df) * 100).round(2)
        })
        missing_df = missing_df[missing_df['Missing Count'] > 0]
        
        if len(missing_df) > 0:
            st.dataframe(missing_df, use_container_width=True)
            fig = px.bar(missing_df, x='C·ªôt', y='Missing %', title="Ph·∫ßn trƒÉm Missing Values")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.success("‚úÖ Kh√¥ng c√≥ missing values!")
        
        # B2.2 - OUTLIERS
        st.header("üìä B2.2 - Ph√°t Hi·ªán Outliers (IQR Method)")
        
        if numeric_cols:
            outlier_data = []
            for col in numeric_cols:
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                outlier_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()
                
                outlier_data.append({
                    'C·ªôt': col,
                    'Q1': Q1,
                    'Q3': Q3,
                    'IQR': IQR,
                    'Lower Bound': lower_bound,
                    'Upper Bound': upper_bound,
                    'Outlier Count': outlier_count
                })
            
            outlier_df = pd.DataFrame(outlier_data)
            st.dataframe(outlier_df, use_container_width=True)
            
            st.subheader("üìä Boxplot Visualization")
            fig, axes = plt.subplots(len(numeric_cols), 1, figsize=(12, 4*len(numeric_cols)))
            if len(numeric_cols) == 1:
                axes = [axes]
            
            for idx, col in enumerate(numeric_cols):
                sns.boxplot(data=df, y=col, ax=axes[idx], color='steelblue')
                axes[idx].set_title(f"Outlier Detection: {col}", fontsize=12, fontweight='bold')
            
            plt.tight_layout()
            st.pyplot(fig)
        
        # B2.3 - DUPLICATES
        st.header("üìä B2.3 - Ki·ªÉm Tra D·ªØ Li·ªáu Tr√πng L·∫∑p")
        
        duplicate_count = df.duplicated().sum()
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("S·ªë d√≤ng tr√πng l·∫∑p", duplicate_count)
        with col2:
            if duplicate_count == 0:
                st.success("‚úÖ Kh√¥ng c√≥ d√≤ng tr√πng l·∫∑p!")
            else:
                st.warning(f"‚ö†Ô∏è Ph√°t hi·ªán {duplicate_count} d√≤ng tr√πng l·∫∑p")
    
    # ============================================================
    # B3: KHAI PH√Å D·ªÆ LI·ªÜU (EDA)
    # ============================================================
    elif page == "üìà B3: Khai ph√° d·ªØ li·ªáu":
        st.title("B3 ‚Äî Khai Ph√° D·ªØ Li·ªáu (Exploratory Data Analysis)")
        st.markdown("---")
        
        numeric_cols = df.select_dtypes(include=["int64", "float64"]).columns.tolist()
        
        # Th√™m c·ªôt Year v√† Price_Range
        df['Year'] = df['Date'].dt.year
        df['Price_Range'] = df['High'] - df['Low']
        
        # B3.1 - LINE CHART
        st.header("üìä B3.1 - Bi·ªÉu ƒê·ªì ƒê∆∞·ªùng: Xu H∆∞·ªõng Gi√°")
        
        fig, ax = plt.subplots(figsize=(14, 6))
        ax.plot(df['Date'], df['Close/Last'], linewidth=2.5, color='steelblue', label='Close Price')
        ax.fill_between(df['Date'], df['Low'], df['High'], alpha=0.2, color='lightblue', label='High-Low Range')
        ax.axhline(y=df['Close/Last'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')
        ax.set_xlabel('Ng√†y (Date)', fontsize=11, fontweight='bold')
        ax.set_ylabel('Gi√° (USD/oz)', fontsize=11, fontweight='bold')
        ax.set_title('Xu H∆∞·ªõng Gi√° V√†ng Theo Th·ªùi Gian', fontsize=13, fontweight='bold')
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        st.pyplot(fig)
        
        # B3.2 - HISTOGRAM
        st.header("üìä B3.2 - Bi·ªÉu ƒê·ªì C·ªôt: Ph√¢n Ph·ªëi Volume")
        
        fig, ax = plt.subplots(figsize=(14, 6))
        ax.hist(df['Volume'], bins=40, alpha=0.7, color='steelblue', edgecolor='black')
        ax.axvline(df['Volume'].mean(), color='red', linestyle='--', linewidth=2.5, label=f'Mean: {df["Volume"].mean():,.0f}')
        ax.axvline(df['Volume'].median(), color='green', linestyle='--', linewidth=2.5, label=f'Median: {df["Volume"].median():,.0f}')
        ax.set_xlabel('Kh·ªëi L∆∞·ª£ng (Volume)', fontsize=11, fontweight='bold')
        ax.set_ylabel('T·∫ßn Su·∫•t (Frequency)', fontsize=11, fontweight='bold')
        ax.set_title('Ph√¢n Ph·ªëi Kh·ªëi L∆∞·ª£ng Giao D·ªãch', fontsize=13, fontweight='bold')
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3, axis='y')
        st.pyplot(fig)
        
        # B3.3 - SCATTER PLOT
        st.header("üìä B3.3 - Bi·ªÉu ƒê·ªì Ph√¢n T√°n: Volume vs Close/Last")
        
        fig, ax = plt.subplots(figsize=(14, 7))
        scatter = ax.scatter(df['Volume'], df['Close/Last'], c=range(len(df)), cmap='viridis', alpha=0.6, s=80, edgecolors='black', linewidth=0.8)
        z = np.polyfit(df['Volume'], df['Close/Last'], 1)
        p = np.poly1d(z)
        volume_sorted = df['Volume'].sort_values()
        correlation = df['Volume'].corr(df['Close/Last'])
        ax.plot(volume_sorted, p(volume_sorted), "r--", linewidth=2.5, label=f'Trend (r={correlation:.3f})')
        ax.set_xlabel('Kh·ªëi L∆∞·ª£ng (Volume)', fontsize=11, fontweight='bold')
        ax.set_ylabel('Gi√° ƒê√≥ng C·ª≠a (USD/oz)', fontsize=11, fontweight='bold')
        ax.set_title('M·ªëi Quan H·ªá Gi·ªØa Kh·ªëi L∆∞·ª£ng v√† Gi√°', fontsize=13, fontweight='bold')
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        cbar = plt.colorbar(scatter, ax=ax, label='Th·ª© t·ª± th·ªùi gian')
        st.pyplot(fig)
        
        # B3.4 - BOXPLOT
        st.header("üìä B3.4 - Boxplot: Bi·∫øn ƒê·ªông Gi√° Theo NƒÉm")
        
        fig, ax = plt.subplots(figsize=(14, 7))
        years = sorted(df['Year'].unique())
        data_by_year = [df[df['Year'] == year]['Price_Range'].values for year in years]
        
        bp = ax.boxplot(data_by_year, labels=years, patch_artist=True, widths=0.6,
                        boxprops=dict(facecolor='lightblue', color='black', linewidth=1.5),
                        whiskerprops=dict(color='black', linewidth=1.5),
                        capprops=dict(color='black', linewidth=1.5),
                        medianprops=dict(color='red', linewidth=2.5),
                        flierprops=dict(marker='o', markerfacecolor='red', markersize=6, alpha=0.5))
        
        ax.set_xlabel('NƒÉm (Year)', fontsize=11, fontweight='bold')
        ax.set_ylabel('Bi·∫øn ƒê·ªông Gi√° (USD/oz)', fontsize=11, fontweight='bold')
        ax.set_title('So S√°nh Bi·∫øn ƒê·ªông Gi√° Theo NƒÉm', fontsize=13, fontweight='bold')
        ax.grid(True, alpha=0.3, axis='y')
        st.pyplot(fig)
    
    # ============================================================
    # B4: T∆Ø∆†NG QUAN & PCA
    # ============================================================
    elif page == "üîó B4: T∆∞∆°ng quan & PCA":
        st.title("B4 ‚Äî Ma Tr·∫≠n T∆∞∆°ng Quan & PCA")
        st.markdown("---")
        
        numeric_cols = df.select_dtypes(include=["int64", "float64"]).columns.tolist()
        
        if len(numeric_cols) < 2:
            st.warning("‚ö†Ô∏è C·∫ßn √≠t nh·∫•t 2 c·ªôt ƒë·ªãnh l∆∞·ª£ng ƒë·ªÉ ph√¢n t√≠ch")
            return
        
        # B4.1 - CORRELATION MATRIX
        st.header("üìä B4.1 - Ma Tr·∫≠n T∆∞∆°ng Quan")
        
        corr_matrix = df[numeric_cols].corr()
        
        fig = go.Figure(data=go.Heatmap(
            z=corr_matrix.values,
            x=corr_matrix.columns,
            y=corr_matrix.columns,
            colorscale='RdBu',
            zmid=0,
            text=np.round(corr_matrix.values, 3),
            texttemplate='%{text}',
            textfont={"size": 10},
        ))
        fig.update_layout(title="Ma Tr·∫≠n T∆∞∆°ng Quan", height=600)
        st.plotly_chart(fig, use_container_width=True)
        
        # B4.2 - HIGH CORRELATION PAIRS
        st.header("üìä B4.2 - C√°c C·∫∑p T∆∞∆°ng Quan Cao")
        
        high_corr_threshold = st.slider("Ng∆∞·ª°ng t∆∞∆°ng quan", 0.5, 1.0, 0.9, 0.05)
        
        high_corr_pairs = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                if abs(corr_matrix.iloc[i, j]) > high_corr_threshold:
                    high_corr_pairs.append({
                        'Var1': corr_matrix.columns[i],
                        'Var2': corr_matrix.columns[j],
                        'Correlation': corr_matrix.iloc[i, j]
                    })
        
        if high_corr_pairs:
            high_corr_df = pd.DataFrame(high_corr_pairs)
            st.dataframe(high_corr_df, use_container_width=True)
        else:
            st.info(f"Kh√¥ng c√≥ c·∫∑p t∆∞∆°ng quan > {high_corr_threshold}")
        
        # B4.3 - PCA
        st.header("üîó B4.3 - Ph√¢n T√≠ch PCA")
        
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(df[numeric_cols])
        
        pca_full = PCA()
        pca_full.fit(X_scaled)
        cumsum_var = np.cumsum(pca_full.explained_variance_ratio_)
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        axes[0].bar(range(1, len(pca_full.explained_variance_ratio_)+1),
                   pca_full.explained_variance_ratio_*100,
                   alpha=0.7, color='steelblue', edgecolor='black')
        axes[0].set_xlabel('Principal Component')
        axes[0].set_ylabel('Explained Variance (%)')
        axes[0].set_title('Scree Plot', fontweight='bold')
        axes[0].grid(True, alpha=0.3, axis='y')
        
        axes[1].plot(range(1, len(cumsum_var)+1), cumsum_var*100, 'bo-', linewidth=2, markersize=8)
        axes[1].axhline(y=95, color='red', linestyle='--', linewidth=2, label='95%')
        axes[1].axhline(y=90, color='orange', linestyle='--', linewidth=2, label='90%')
        axes[1].set_xlabel('Number of Components')
        axes[1].set_ylabel('Cumulative Explained Variance (%)')
        axes[1].set_title('Cumulative Variance', fontweight='bold')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        st.pyplot(fig)
        
        # 2D PCA Projection
        pca = PCA(n_components=2)
        X_pca = pca.fit_transform(X_scaled)
        
        fig = px.scatter(x=X_pca[:, 0], y=X_pca[:, 1],
                        labels={'x': f'PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)',
                               'y': f'PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)'},
                        title='PCA 2D Projection')
        st.plotly_chart(fig, use_container_width=True)
    
    # ============================================================
    # B5: M√î H√åNH & D·ª∞ B√ÅO
    # ============================================================
    elif page == "ü§ñ B5: M√¥ h√¨nh & D·ª± b√°o":
        st.title("B5 ‚Äî M√¥ H√¨nh Machine Learning & D·ª± B√°o")
        st.markdown("---")
        
        numeric_cols = df.select_dtypes(include=["int64", "float64"]).columns.tolist()
        
        tab1, tab2 = st.tabs(["üéØ K-Means Clustering", "üìà Linear Regression"])
        
        # ============================================================
        # K-MEANS
        # ============================================================
        with tab1:
            st.header("üéØ K-Means Clustering")
            
            k = st.sidebar.slider("S·ªë c·ª•m (K)", min_value=2, max_value=8, value=3, step=1)
            
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(df[numeric_cols])
            
            with st.spinner("ƒêang hu·∫•n luy·ªán K-Means..."):
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                df_plot = df.copy()
                df_plot['Cluster'] = kmeans.fit_predict(X_scaled)
            
            st.success(f"‚úÖ Ph√¢n c·ª•m th√†nh {k} nh√≥m")
            
            col1, col2 = st.columns(2)
            
            with col1:
                cluster_counts = df_plot['Cluster'].value_counts().sort_index()
                fig = px.bar(x=cluster_counts.index, y=cluster_counts.values,
                           title="Ph√¢n Ph·ªëi Clusters",
                           labels={'x': 'Cluster', 'y': 'Count'})
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                silhouette = silhouette_score(X_scaled, df_plot['Cluster'])
                st.metric("Silhouette Score", f"{silhouette:.4f}")
                if silhouette > 0.5:
                    st.success("‚úÖ Ph√¢n c·ª•m t·ªët")
                else:
                    st.warning("‚ö†Ô∏è Ph√¢n c·ª•m c√≥ th·ªÉ ƒë∆∞·ª£c c·∫£i thi·ªán")
            
            st.subheader("üìä Th·ªëng K√™ Clusters")
            cluster_stats = df_plot.groupby('Cluster')[numeric_cols].mean()
            st.dataframe(cluster_stats, use_container_width=True)
        
        # ============================================================
        # LINEAR REGRESSION
        # ============================================================
        with tab2:
            st.header("üìà Linear Regression - D·ª± B√°o Gi√°")
            
            target_col = [col for col in numeric_cols if 'close' in col.lower() or 'price' in col.lower()]
            if not target_col:
                target_col = numeric_cols[0]
            else:
                target_col = target_col[0]
            
            if 'Date' in df.columns:
                df_model = df.copy()
                df_model['Days'] = (df_model['Date'] - df_model['Date'].min()).dt.days
                X = df_model[['Days']].values
            else:
                X = np.arange(len(df)).reshape(-1, 1)
                df_model = df.copy()
                df_model['Days'] = np.arange(len(df))
            
            y = df_model[target_col].values
            
            with st.spinner("ƒêang hu·∫•n luy·ªán Linear Regression..."):
                lr = LinearRegression()
                lr.fit(X, y)
                y_pred = lr.predict(X)
            
            mse = mean_squared_error(y, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y, y_pred)
            r2 = r2_score(y, y_pred)
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("R¬≤ Score", f"{r2:.4f}")
            with col2:
                st.metric("RMSE", f"${rmse:.2f}")
            with col3:
                st.metric("MAE", f"${mae:.2f}")
            with col4:
                st.metric("Slope", f"${lr.coef_[0]:.4f}/day")
            
            end_year = st.sidebar.selectbox("D·ª± b√°o ƒë·∫øn nƒÉm", [2025, 2026, 2027, 2028, 2030], index=2)
            
            if 'Date' in df.columns:
                last_date = df_model['Date'].max()
                target_date = pd.Timestamp(f'{end_year}-12-31')
                future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), end=target_date, freq='D')
                future_days = (future_dates - df_model['Date'].min()).days.values.reshape(-1, 1)
                future_prices = lr.predict(future_days)
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=df_model['Date'], y=y, name='Actual',
                                        mode='lines', line=dict(color='steelblue', width=2)))
                fig.add_trace(go.Scatter(x=df_model['Date'], y=y_pred, name='Fit',
                                        mode='lines', line=dict(color='orange', width=2, dash='dash')))
                fig.add_trace(go.Scatter(x=future_dates, y=future_prices, name=f'Forecast to {end_year}',
                                        mode='lines', line=dict(color='red', width=2)))
                
                fig.update_layout(title=f"D·ª± B√°o Gi√° V√†ng ƒê·∫øn {end_year}", height=500,
                                 xaxis_title="Ng√†y", yaxis_title=f"Gi√° ({target_col})")
                st.plotly_chart(fig, use_container_width=True)
                
                st.subheader("üîÆ Th·ªëng K√™ D·ª± B√°o")
                pred_price = lr.predict([[((pd.Timestamp(f'{end_year}-12-31') - df_model['Date'].min()).days)]])[0]
                std_error = np.std(y - y_pred)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric(f"Gi√° d·ª± ki·∫øn {end_year}", f"${pred_price:.2f}")
                with col2:
                    st.metric("Kho·∫£ng tin c·∫≠y ¬±", f"${1.96*std_error:.2f}")
            
            st.warning("‚ö†Ô∏è L∆∞u √Ω: D·ª± b√°o d√†i h·∫°n c√≥ ƒë·ªô tin c·∫≠y th·∫•p do gi·∫£ ƒë·ªãnh xu h∆∞·ªõng tuy·∫øn t√≠nh")

if __name__ == "__main__":
    main()
